{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7594140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Collected and cleaned 200 posts (with comments) from 4 subreddits.\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id='yZgp5fHdkhZQwGSCQ6Of4Q',\n",
    "    client_secret='yZgmiMH34SQlf2efwsf1zIeqWXEvoQ',\n",
    "    user_agent='Bitcoin Sentiment Analysis'\n",
    ")\n",
    "\n",
    "# List of subreddits\n",
    "subreddits = ['Bitcoin', 'CryptoCurrency', 'BitcoinMarkets', 'btc']\n",
    "posts = []\n",
    "\n",
    "# Clean text utility\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s.,!?]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.lower().strip()\n",
    "\n",
    "# Loop through each subreddit\n",
    "for subreddit_name in subreddits:\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    \n",
    "    # Fetch 50 posts per subreddit with keyword \"Bitcoin\"\n",
    "    for submission in subreddit.search('Bitcoin', limit=50):\n",
    "        try:\n",
    "            submission.comments.replace_more(limit=0)\n",
    "            # Extract up to 20 top-level comments\n",
    "            top_comments = [comment.body for comment in submission.comments.list()[:20]]\n",
    "            comment_text = \" \".join([clean_text(comment) for comment in top_comments])\n",
    "            \n",
    "            title_clean = clean_text(submission.title)\n",
    "            selftext_clean = clean_text(submission.selftext)\n",
    "            combined_text = f\"{title_clean} {selftext_clean} {comment_text}\"\n",
    "            \n",
    "            posts.append([\n",
    "                title_clean,\n",
    "                selftext_clean,\n",
    "                comment_text,\n",
    "                combined_text,\n",
    "                datetime.utcfromtimestamp(submission.created_utc),\n",
    "                subreddit_name\n",
    "            ])\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Skipping a post in r/{subreddit_name} due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_reddit = pd.DataFrame(posts, columns=['title', 'selftext', 'comments', 'content', 'created_utc', 'subreddit'])\n",
    "print(f\"‚úÖ Collected and cleaned {len(df_reddit)} posts (with comments) from {len(subreddits)} subreddits.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "279205ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "\n",
    "def get_finbert_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    scores = softmax(logits.numpy()[0])\n",
    "    sentiment = scores[2] - scores[0]  # Positive - Negative\n",
    "    return sentiment\n",
    "\n",
    "df_reddit['content'] = df_reddit['title'] + ' ' + df_reddit['selftext'] + ' ' + df_reddit['comments']\n",
    "\n",
    "df_reddit['sentiment'] = df_reddit['content'].apply(get_finbert_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b5a0e238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "btc_data.columns: Index(['Datetime', 'Close', 'High', 'Low', 'Open', 'Volume'], dtype='object', name='Price')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define time range\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=10)\n",
    "\n",
    "# Download BTC data\n",
    "btc_data = yf.download('BTC-USD', start=start_date, end=end_date, interval='1h')\n",
    "\n",
    "# Fix multilevel columns\n",
    "if isinstance(btc_data.columns, pd.MultiIndex):\n",
    "    btc_data.columns = btc_data.columns.get_level_values(0)  # Keep just the first level\n",
    "\n",
    "# Reset index\n",
    "btc_data.reset_index(inplace=True)\n",
    "\n",
    "# Rename 'index' or confirm 'Datetime' exists\n",
    "btc_data.rename(columns={'index': 'Datetime'}, inplace=True)\n",
    "\n",
    "# Confirm column structure\n",
    "print(\"btc_data.columns:\", btc_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d426213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vineeth\\AppData\\Local\\Temp\\ipykernel_21464\\112633328.py:6: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_reddit['hour'] = df_reddit['created_utc'].dt.floor('H')\n",
      "C:\\Users\\Vineeth\\AppData\\Local\\Temp\\ipykernel_21464\\112633328.py:7: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  btc_data['hour'] = btc_data['Datetime'].dt.floor('H')\n",
      "C:\\Users\\Vineeth\\AppData\\Local\\Temp\\ipykernel_21464\\112633328.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['sentiment'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Remove timezone from Reddit timestamps\n",
    "df_reddit['created_utc'] = pd.to_datetime(df_reddit['created_utc']).dt.tz_localize(None)\n",
    "btc_data['Datetime'] = pd.to_datetime(btc_data['Datetime']).dt.tz_localize(None)\n",
    "\n",
    "# Create hourly timestamps\n",
    "df_reddit['hour'] = df_reddit['created_utc'].dt.floor('H')\n",
    "btc_data['hour'] = btc_data['Datetime'].dt.floor('H')\n",
    "\n",
    "# Group Reddit sentiment by hour\n",
    "sentiment_hourly = df_reddit.groupby('hour', as_index=False)['sentiment'].mean()\n",
    "\n",
    "# ‚úÖ Ensure btc_data has no MultiIndex\n",
    "btc_data.columns = [col if isinstance(col, str) else col[0] for col in btc_data.columns]\n",
    "\n",
    "# ‚úÖ Merge on the hour column\n",
    "data = pd.merge(btc_data, sentiment_hourly, on='hour', how='left')\n",
    "\n",
    "# Fill missing sentiment with neutral\n",
    "data['sentiment'].fillna(0, inplace=True)\n",
    "\n",
    "# Select required columns\n",
    "data = data[['Datetime', 'Close', 'sentiment']]\n",
    "\n",
    "# Normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data[['Close', 'sentiment']] = scaler.fit_transform(data[['Close', 'sentiment']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "580392c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "5/5 [==============================] - 9s 418ms/step - loss: 0.5217 - val_loss: 0.0118\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0678 - val_loss: 0.0300\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0251 - val_loss: 0.0235\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0304 - val_loss: 0.0221\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0195 - val_loss: 0.0030\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.0157 - val_loss: 0.0102\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0210 - val_loss: 0.0028\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0126 - val_loss: 0.0089\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0136 - val_loss: 0.0064\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0144 - val_loss: 0.0029\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.0149 - val_loss: 0.0042\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.0131 - val_loss: 0.0030\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0135 - val_loss: 0.0051\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0116 - val_loss: 0.0033\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0108 - val_loss: 0.0030\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0114 - val_loss: 0.0029\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0132 - val_loss: 0.0034\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0099 - val_loss: 0.0027\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0130 - val_loss: 0.0027\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0142 - val_loss: 0.0031\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0088 - val_loss: 0.0027\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0133 - val_loss: 0.0027\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0114 - val_loss: 0.0048\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0106 - val_loss: 0.0032\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0111 - val_loss: 0.0028\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0105 - val_loss: 0.0027\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0086 - val_loss: 0.0031\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0104 - val_loss: 0.0032\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0090 - val_loss: 0.0026\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0127 - val_loss: 0.0031\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0095 - val_loss: 0.0027\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0103 - val_loss: 0.0027\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0105 - val_loss: 0.0033\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0094 - val_loss: 0.0030\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0091 - val_loss: 0.0028\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0100 - val_loss: 0.0025\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0093 - val_loss: 0.0025\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0090 - val_loss: 0.0029\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0106 - val_loss: 0.0027\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0115 - val_loss: 0.0026\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0092 - val_loss: 0.0026\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0088 - val_loss: 0.0026\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0089 - val_loss: 0.0034\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0092 - val_loss: 0.0025\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0094 - val_loss: 0.0026\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.0098 - val_loss: 0.0037\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0108 - val_loss: 0.0025\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0088 - val_loss: 0.0031\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0096 - val_loss: 0.0034\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0107 - val_loss: 0.0023\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0101 - val_loss: 0.0023\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0091 - val_loss: 0.0027\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0087 - val_loss: 0.0025\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0086 - val_loss: 0.0025\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0092 - val_loss: 0.0022\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0093 - val_loss: 0.0022\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0100 - val_loss: 0.0027\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0088 - val_loss: 0.0031\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0095 - val_loss: 0.0030\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0087 - val_loss: 0.0020\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0072 - val_loss: 0.0023\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0088 - val_loss: 0.0021\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0094 - val_loss: 0.0020\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0096 - val_loss: 0.0037\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0085 - val_loss: 0.0024\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0100 - val_loss: 0.0028\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0078 - val_loss: 0.0022\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0084 - val_loss: 0.0019\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0072 - val_loss: 0.0018\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0072 - val_loss: 0.0020\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0079 - val_loss: 0.0017\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0061 - val_loss: 0.0018\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0091 - val_loss: 0.0016\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0072 - val_loss: 0.0016\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0066 - val_loss: 0.0024\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0073 - val_loss: 0.0016\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0068 - val_loss: 0.0015\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.0065 - val_loss: 0.0015\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0075 - val_loss: 0.0016\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0077 - val_loss: 0.0015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b300638dc0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "def create_sequences(data, time_steps=60):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data[i:i + time_steps])\n",
    "        y.append(data[i + time_steps, 0])  # Close price\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "dataset = data[['Close', 'sentiment']].values\n",
    "time_steps = 60\n",
    "X, y = create_sequences(dataset, time_steps)\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, epochs=80, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bca1fdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Hourly Forecasted BTC Price Fluctuations:\n",
      "\n",
      "Hour  1: Predicted Price = $103,248.11 | Change = +0.09% ‚Üë\n",
      "Hour  2: Predicted Price = $103,246.84 | Change = -0.00% ‚Üì\n",
      "Hour  3: Predicted Price = $103,254.48 | Change = +0.01% ‚Üë\n",
      "Hour  4: Predicted Price = $103,268.70 | Change = +0.01% ‚Üë\n",
      "Hour  5: Predicted Price = $103,287.53 | Change = +0.02% ‚Üë\n",
      "Hour  6: Predicted Price = $103,309.36 | Change = +0.02% ‚Üë\n",
      "Hour  7: Predicted Price = $103,332.95 | Change = +0.02% ‚Üë\n",
      "Hour  8: Predicted Price = $103,357.27 | Change = +0.02% ‚Üë\n",
      "Hour  9: Predicted Price = $103,381.58 | Change = +0.02% ‚Üë\n",
      "Hour 10: Predicted Price = $103,405.34 | Change = +0.02% ‚Üë\n",
      "Hour 11: Predicted Price = $103,428.12 | Change = +0.02% ‚Üë\n",
      "Hour 12: Predicted Price = $103,449.58 | Change = +0.02% ‚Üë\n",
      "Hour 13: Predicted Price = $103,469.52 | Change = +0.02% ‚Üë\n",
      "Hour 14: Predicted Price = $103,487.83 | Change = +0.02% ‚Üë\n",
      "Hour 15: Predicted Price = $103,504.40 | Change = +0.02% ‚Üë\n",
      "Hour 16: Predicted Price = $103,519.15 | Change = +0.01% ‚Üë\n",
      "Hour 17: Predicted Price = $103,532.02 | Change = +0.01% ‚Üë\n",
      "Hour 18: Predicted Price = $103,543.10 | Change = +0.01% ‚Üë\n",
      "Hour 19: Predicted Price = $103,552.41 | Change = +0.01% ‚Üë\n",
      "Hour 20: Predicted Price = $103,559.99 | Change = +0.01% ‚Üë\n",
      "Hour 21: Predicted Price = $103,565.94 | Change = +0.01% ‚Üë\n",
      "Hour 22: Predicted Price = $103,570.33 | Change = +0.00% ‚Üë\n",
      "Hour 23: Predicted Price = $103,573.26 | Change = +0.00% ‚Üë\n",
      "Hour 24: Predicted Price = $103,574.85 | Change = +0.00% ‚Üë\n",
      "Hour 25: Predicted Price = $103,575.21 | Change = +0.00% ‚Üë\n",
      "Hour 26: Predicted Price = $103,574.44 | Change = -0.00% ‚Üì\n",
      "Hour 27: Predicted Price = $103,572.80 | Change = -0.00% ‚Üì\n",
      "Hour 28: Predicted Price = $103,570.13 | Change = -0.00% ‚Üì\n",
      "Hour 29: Predicted Price = $103,566.71 | Change = -0.00% ‚Üì\n",
      "Hour 30: Predicted Price = $103,562.66 | Change = -0.00% ‚Üì\n",
      "Hour 31: Predicted Price = $103,558.08 | Change = -0.00% ‚Üì\n",
      "Hour 32: Predicted Price = $103,553.10 | Change = -0.00% ‚Üì\n",
      "Hour 33: Predicted Price = $103,547.81 | Change = -0.01% ‚Üì\n",
      "Hour 34: Predicted Price = $103,542.32 | Change = -0.01% ‚Üì\n",
      "Hour 35: Predicted Price = $103,536.70 | Change = -0.01% ‚Üì\n",
      "Hour 36: Predicted Price = $103,531.07 | Change = -0.01% ‚Üì\n",
      "Hour 37: Predicted Price = $103,525.47 | Change = -0.01% ‚Üì\n",
      "Hour 38: Predicted Price = $103,519.99 | Change = -0.01% ‚Üì\n",
      "Hour 39: Predicted Price = $103,514.69 | Change = -0.01% ‚Üì\n",
      "Hour 40: Predicted Price = $103,509.62 | Change = -0.00% ‚Üì\n",
      "Hour 41: Predicted Price = $103,504.80 | Change = -0.00% ‚Üì\n",
      "Hour 42: Predicted Price = $103,500.30 | Change = -0.00% ‚Üì\n",
      "Hour 43: Predicted Price = $103,496.13 | Change = -0.00% ‚Üì\n",
      "Hour 44: Predicted Price = $103,492.31 | Change = -0.00% ‚Üì\n",
      "Hour 45: Predicted Price = $103,488.87 | Change = -0.00% ‚Üì\n",
      "Hour 46: Predicted Price = $103,485.80 | Change = -0.00% ‚Üì\n",
      "Hour 47: Predicted Price = $103,483.12 | Change = -0.00% ‚Üì\n",
      "Hour 48: Predicted Price = $103,480.80 | Change = -0.00% ‚Üì\n",
      "Hour 49: Predicted Price = $103,478.87 | Change = -0.00% ‚Üì\n",
      "Hour 50: Predicted Price = $103,477.31 | Change = -0.00% ‚Üì\n",
      "Hour 51: Predicted Price = $103,476.09 | Change = -0.00% ‚Üì\n",
      "Hour 52: Predicted Price = $103,475.20 | Change = -0.00% ‚Üì\n",
      "Hour 53: Predicted Price = $103,474.62 | Change = -0.00% ‚Üì\n",
      "Hour 54: Predicted Price = $103,474.32 | Change = -0.00% ‚Üì\n",
      "Hour 55: Predicted Price = $103,474.28 | Change = -0.00% ‚Üì\n",
      "Hour 56: Predicted Price = $103,474.47 | Change = +0.00% ‚Üë\n",
      "Hour 57: Predicted Price = $103,474.87 | Change = +0.00% ‚Üë\n",
      "Hour 58: Predicted Price = $103,475.45 | Change = +0.00% ‚Üë\n",
      "Hour 59: Predicted Price = $103,476.20 | Change = +0.00% ‚Üë\n",
      "Hour 60: Predicted Price = $103,477.07 | Change = +0.00% ‚Üë\n",
      "Hour 61: Predicted Price = $103,478.06 | Change = +0.00% ‚Üë\n",
      "Hour 62: Predicted Price = $103,479.13 | Change = +0.00% ‚Üë\n",
      "Hour 63: Predicted Price = $103,480.27 | Change = +0.00% ‚Üë\n",
      "Hour 64: Predicted Price = $103,481.44 | Change = +0.00% ‚Üë\n",
      "Hour 65: Predicted Price = $103,482.64 | Change = +0.00% ‚Üë\n",
      "Hour 66: Predicted Price = $103,483.84 | Change = +0.00% ‚Üë\n",
      "Hour 67: Predicted Price = $103,485.04 | Change = +0.00% ‚Üë\n",
      "Hour 68: Predicted Price = $103,486.20 | Change = +0.00% ‚Üë\n",
      "Hour 69: Predicted Price = $103,487.33 | Change = +0.00% ‚Üë\n",
      "Hour 70: Predicted Price = $103,488.40 | Change = +0.00% ‚Üë\n",
      "Hour 71: Predicted Price = $103,489.42 | Change = +0.00% ‚Üë\n",
      "Hour 72: Predicted Price = $103,490.38 | Change = +0.00% ‚Üë\n",
      "\n",
      "üîÆ Final Forecast Summary:\n",
      "‚úÖ Yes, the price is increasing by 0.33% in the next 72 hours.\n"
     ]
    }
   ],
   "source": [
    "# Get forecast horizon from the user\n",
    "forecast_hours = int(input(\"Enter how many hours ahead you'd like to forecast (e.g., 24, 48, 168): \"))\n",
    "\n",
    "# Forecast loop\n",
    "last_sequence = dataset[-time_steps:]\n",
    "forecast_input = last_sequence.copy()\n",
    "forecast_prices = []\n",
    "\n",
    "for _ in range(forecast_hours):\n",
    "    input_seq = np.expand_dims(forecast_input[-time_steps:], axis=0)\n",
    "    pred = model.predict(input_seq, verbose=0)[0][0]\n",
    "    forecast_prices.append(pred)\n",
    "    forecast_input = np.vstack([forecast_input, [pred, forecast_input[-1][1]]])  # Use last sentiment\n",
    "\n",
    "# Decode forecasted prices\n",
    "decoded_prices = [scaler.inverse_transform([[p, 0]])[0][0] for p in forecast_prices]\n",
    "last_actual_price = scaler.inverse_transform([[dataset[-1][0], 0]])[0][0]\n",
    "\n",
    "# Calculate percentage fluctuations hour by hour\n",
    "print(\"\\nüìà Hourly Forecasted BTC Price Fluctuations:\\n\")\n",
    "prev_price = last_actual_price\n",
    "for i, price in enumerate(decoded_prices):\n",
    "    change = ((price - prev_price) / prev_price) * 100\n",
    "    direction = \"‚Üë\" if change > 0 else \"‚Üì\" if change < 0 else \"‚Üí\"\n",
    "    print(f\"Hour {i+1:>2}: Predicted Price = ${price:,.2f} | Change = {change:+.2f}% {direction}\")\n",
    "    prev_price = price\n",
    "\n",
    "# Final summary\n",
    "final_predicted_price = decoded_prices[-1]\n",
    "percentage_change = ((final_predicted_price - last_actual_price) / last_actual_price) * 100\n",
    "\n",
    "print(\"\\nüîÆ Final Forecast Summary:\")\n",
    "if percentage_change > 0.1:\n",
    "    print(f\"‚úÖ Yes, the price is increasing by {percentage_change:.2f}% in the next {forecast_hours} hours.\")\n",
    "elif percentage_change < -0.1:\n",
    "    print(f\"‚ùå No, the price is decreasing by {abs(percentage_change):.2f}% in the next {forecast_hours} hours.\")\n",
    "else:\n",
    "    print(f\"‚öñÔ∏è The predicted change is negligible ({percentage_change:.2f}%) in the next {forecast_hours} hours.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55574cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
